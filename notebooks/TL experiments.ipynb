{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6efa4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import flax\n",
    "import jax.numpy as jnp\n",
    "from transformers import (\n",
    "    BatchEncoding,\n",
    "    PreTrainedTokenizerBase,\n",
    ")\n",
    "\n",
    "from transformers.models.t5.modeling_flax_t5 import shift_tokens_right\n",
    "\n",
    "\n",
    "@flax.struct.dataclass\n",
    "class FlaxDataCollatorForT5MLM:\n",
    "    \"\"\"\n",
    "    Data collator used for T5 span-masked language modeling.\n",
    "    It is made sure that after masking the inputs are of length `data_args.max_seq_length` and targets are also of fixed length.\n",
    "    For more information on how T5 span-masked language modeling works, one can take a look\n",
    "    at the `official paper <https://arxiv.org/pdf/1910.10683.pdf>`__\n",
    "    or the `official code for preprocessing <https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/data/preprocessors.py>`__ .\n",
    "\n",
    "    Args:\n",
    "        tokenizer (:class:`~transformers.PreTrainedTokenizer` or :class:`~transformers.PreTrainedTokenizerFast`):\n",
    "            The tokenizer used for encoding the data.\n",
    "        noise_density (:obj:`float`):\n",
    "            The probability with which to (randomly) mask tokens in the input.\n",
    "        mean_noise_span_length (:obj:`float`):\n",
    "            The average span length of the masked tokens.\n",
    "        input_length (:obj:`int`):\n",
    "            The expected input length after masking.\n",
    "        target_length (:obj:`int`):\n",
    "            The expected target length after masking.\n",
    "        pad_token_id: (:obj:`int`):\n",
    "            The pad token id of the model\n",
    "        decoder_start_token_id: (:obj:`int):\n",
    "            The decoder start token id of the model\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    noise_density: float\n",
    "    mean_noise_span_length: float\n",
    "    input_length: int\n",
    "    target_length: int\n",
    "    pad_token_id: int\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, examples: List[Dict[str, np.ndarray]]) -> Dict[str, np.ndarray]:\n",
    "\n",
    "        # convert list to dict and tensorize input\n",
    "        max_len_array = max([len(list(i.values())[0]) for i in examples])\n",
    "        batch = BatchEncoding(\n",
    "            {k: np.array([examples[i][k]+[self.pad_token_id] * (max_len_array - len(examples[i][k])) for i in range(len(examples))]) for k, v in examples[0].items()}\n",
    "        )\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        batch_size, expandend_input_length = input_ids.shape\n",
    "\n",
    "        mask_indices = np.asarray([self.random_spans_noise_mask(expandend_input_length) for i in range(batch_size)])\n",
    "        labels_mask = ~mask_indices\n",
    "\n",
    "        input_ids_sentinel = self.create_sentinel_ids(mask_indices.astype(np.int8))\n",
    "        labels_sentinel = self.create_sentinel_ids(labels_mask.astype(np.int8))\n",
    "\n",
    "        batch[\"input_ids\"] = self.filter_input_ids(input_ids, input_ids_sentinel)\n",
    "        batch[\"labels\"] = self.filter_input_ids(input_ids, labels_sentinel)\n",
    "        batch[\"decoder_input_ids\"] = shift_tokens_right(\n",
    "            batch[\"labels\"], self.pad_token_id, self.decoder_start_token_id\n",
    "        )\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def create_sentinel_ids(self, mask_indices):\n",
    "        \"\"\"\n",
    "        Sentinel ids creation given the indices that should be masked.\n",
    "        The start indices of each mask are replaced by the sentinel ids in increasing\n",
    "        order. Consecutive mask indices to be deleted are replaced with `-1`.\n",
    "        \"\"\"\n",
    "        start_indices = mask_indices - np.roll(mask_indices, 1, axis=-1) * mask_indices\n",
    "        start_indices[:, 0] = mask_indices[:, 0]\n",
    "\n",
    "        sentinel_ids = np.where(start_indices != 0, np.cumsum(start_indices, axis=-1), start_indices)\n",
    "        sentinel_ids = np.where(sentinel_ids != 0, (self.tokenizer.vocab_size - 1 - sentinel_ids), 0)\n",
    "        sentinel_ids -= mask_indices - start_indices\n",
    "\n",
    "        return sentinel_ids\n",
    "\n",
    "    def filter_input_ids(self, input_ids, sentinel_ids):\n",
    "        \"\"\"\n",
    "        Puts sentinel mask on `input_ids` and fuse consecutive mask tokens into a single mask token by deleting.\n",
    "        This will reduce the sequence length from `expanded_inputs_length` to `input_length`.\n",
    "        \"\"\"\n",
    "        batch_size = input_ids.shape[0]\n",
    "\n",
    "        input_ids_full = np.where(sentinel_ids != 0, sentinel_ids, input_ids)\n",
    "        input_ids = input_ids_full[(input_ids_full >= 0)].reshape((batch_size, -1))\n",
    "        input_ids = np.concatenate(\n",
    "            [input_ids, np.full((batch_size, 1), self.tokenizer.eos_token_id, dtype=np.int32)], axis=-1\n",
    "        )\n",
    "        return input_ids\n",
    "\n",
    "    def random_spans_noise_mask(self, length):\n",
    "\n",
    "        \"\"\"This function is copy of `random_spans_helper <https://github.com/google-research/text-to-text-transfer-transformer/blob/84f8bcc14b5f2c03de51bd3587609ba8f6bbd1cd/t5/data/preprocessors.py#L2682>`__ .\n",
    "\n",
    "        Noise mask consisting of random spans of noise tokens.\n",
    "        The number of noise tokens and the number of noise spans and non-noise spans\n",
    "        are determined deterministically as follows:\n",
    "        num_noise_tokens = round(length * noise_density)\n",
    "        num_nonnoise_spans = num_noise_spans = round(num_noise_tokens / mean_noise_span_length)\n",
    "        Spans alternate between non-noise and noise, beginning with non-noise.\n",
    "        Subject to the above restrictions, all masks are equally likely.\n",
    "\n",
    "        Args:\n",
    "            length: an int32 scalar (length of the incoming token sequence)\n",
    "            noise_density: a float - approximate density of output mask\n",
    "            mean_noise_span_length: a number\n",
    "\n",
    "        Returns:\n",
    "            a boolean tensor with shape [length]\n",
    "        \"\"\"\n",
    "\n",
    "        orig_length = length\n",
    "\n",
    "        num_noise_tokens = int(np.round(length * self.noise_density))\n",
    "        # avoid degeneracy by ensuring positive numbers of noise and nonnoise tokens.\n",
    "        num_noise_tokens = min(max(num_noise_tokens, 1), length - 1)\n",
    "        num_noise_spans = int(np.round(num_noise_tokens / self.mean_noise_span_length))\n",
    "\n",
    "        # avoid degeneracy by ensuring positive number of noise spans\n",
    "        num_noise_spans = max(num_noise_spans, 1)\n",
    "        num_nonnoise_tokens = length - num_noise_tokens\n",
    "\n",
    "        # pick the lengths of the noise spans and the non-noise spans\n",
    "        def _random_segmentation(num_items, num_segments):\n",
    "            \"\"\"Partition a sequence of items randomly into non-empty segments.\n",
    "            Args:\n",
    "                num_items: an integer scalar > 0\n",
    "                num_segments: an integer scalar in [1, num_items]\n",
    "            Returns:\n",
    "                a Tensor with shape [num_segments] containing positive integers that add\n",
    "                up to num_items\n",
    "            \"\"\"\n",
    "            mask_indices = np.arange(num_items - 1) < (num_segments - 1)\n",
    "            np.random.shuffle(mask_indices)\n",
    "            first_in_segment = np.pad(mask_indices, [[1, 0]])\n",
    "            segment_id = np.cumsum(first_in_segment)\n",
    "            # count length of sub segments assuming that list is sorted\n",
    "            _, segment_length = np.unique(segment_id, return_counts=True)\n",
    "            return segment_length\n",
    "\n",
    "        noise_span_lengths = _random_segmentation(num_noise_tokens, num_noise_spans)\n",
    "        nonnoise_span_lengths = _random_segmentation(num_nonnoise_tokens, num_noise_spans)\n",
    "\n",
    "        interleaved_span_lengths = np.reshape(\n",
    "            np.stack([nonnoise_span_lengths, noise_span_lengths], axis=1), [num_noise_spans * 2]\n",
    "        )\n",
    "        span_starts = np.cumsum(interleaved_span_lengths)[:-1]\n",
    "        span_start_indicator = np.zeros((length,), dtype=np.int8)\n",
    "        span_start_indicator[span_starts] = True\n",
    "        span_num = np.cumsum(span_start_indicator)\n",
    "        is_noise = np.equal(span_num % 2, 1)\n",
    "\n",
    "        return is_noise[:orig_length]\n",
    "\n",
    "\n",
    "def generate_batch_splits(samples_idx: jnp.ndarray, batch_size: int) -> jnp.ndarray:\n",
    "    num_samples = len(samples_idx)\n",
    "    samples_to_remove = num_samples % batch_size\n",
    "\n",
    "    if samples_to_remove != 0:\n",
    "        samples_idx = samples_idx[:-samples_to_remove]\n",
    "    sections_split = num_samples // batch_size\n",
    "    batch_idx = np.split(samples_idx, sections_split)\n",
    "    return batch_idx\n",
    "\n",
    "\n",
    "def compute_input_and_target_lengths(inputs_length, noise_density, mean_noise_span_length):\n",
    "    \"\"\"This function is copy of `random_spans_helper <https://github.com/google-research/text-to-text-transfer-transformer/blob/84f8bcc14b5f2c03de51bd3587609ba8f6bbd1cd/t5/data/preprocessors.py#L2466>`__ .\n",
    "\n",
    "    Training parameters to avoid padding with random_spans_noise_mask.\n",
    "    When training a model with random_spans_noise_mask, we would like to set the other\n",
    "    training hyperparmeters in a way that avoids padding.\n",
    "    This function helps us compute these hyperparameters.\n",
    "    We assume that each noise span in the input is replaced by extra_tokens_per_span_inputs sentinel tokens,\n",
    "    and each non-noise span in the targets is replaced by extra_tokens_per_span_targets sentinel tokens.\n",
    "    This function tells us the required number of tokens in the raw example (for split_tokens())\n",
    "    as well as the length of the encoded targets. Note that this function assumes\n",
    "    the inputs and targets will have EOS appended and includes that in the reported length.\n",
    "\n",
    "    Args:\n",
    "        inputs_length: an integer - desired length of the tokenized inputs sequence\n",
    "        noise_density: a float\n",
    "        mean_noise_span_length: a float\n",
    "    Returns:\n",
    "        tokens_length: length of original text in tokens\n",
    "        targets_length: an integer - length in tokens of encoded targets sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def _tokens_length_to_inputs_length_targets_length(tokens_length):\n",
    "        num_noise_tokens = int(round(tokens_length * noise_density))\n",
    "        num_nonnoise_tokens = tokens_length - num_noise_tokens\n",
    "        num_noise_spans = int(round(num_noise_tokens / mean_noise_span_length))\n",
    "        # inputs contain all nonnoise tokens, sentinels for all noise spans\n",
    "        # and one EOS token.\n",
    "        _input_length = num_nonnoise_tokens + num_noise_spans + 1\n",
    "        _output_length = num_noise_tokens + num_noise_spans + 1\n",
    "        return _input_length, _output_length\n",
    "\n",
    "    tokens_length = inputs_length\n",
    "\n",
    "    while _tokens_length_to_inputs_length_targets_length(tokens_length + 1)[0] <= inputs_length:\n",
    "        tokens_length += 1\n",
    "\n",
    "    inputs_length, targets_length = _tokens_length_to_inputs_length_targets_length(tokens_length)\n",
    "\n",
    "    # minor hack to get the targets length to be equal to inputs length\n",
    "    # which is more likely to have been set to a nice round number.\n",
    "    if noise_density == 0.5 and targets_length > inputs_length:\n",
    "        tokens_length -= 1\n",
    "        targets_length -= 1\n",
    "    return tokens_length, targets_length\n",
    "\n",
    "\n",
    "def tokenize_function(examples, tokenizer, text_column_name):\n",
    "    return tokenizer(examples[text_column_name], return_attention_mask=False)\n",
    "\n",
    "\n",
    "# Main data processing function that will concatenate all texts from our dataset and generate chunks of expanded_inputs_length.\n",
    "def group_texts(examples, expanded_inputs_length):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= expanded_inputs_length:\n",
    "        total_length = (total_length // expanded_inputs_length) * expanded_inputs_length\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + expanded_inputs_length] for i in range(0, total_length, expanded_inputs_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7893dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import (\n",
    "#     MT5ForConditionalGeneration,\n",
    "#     T5Tokenizer,\n",
    "#     AdamW,\n",
    "#     get_linear_schedule_with_warmup\n",
    "# )\n",
    "# import torch\n",
    "# from datasets import load_dataset\n",
    "# import os\n",
    "# import json\n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm, trange\n",
    "# from flax.training.common_utils import shard\n",
    "# from enum import Enum\n",
    "# from typing import Optional, Tuple\n",
    "# from fire import Fire\n",
    "# from math import floor\n",
    "# import uuid\n",
    "\n",
    "# #import mt5_utils\n",
    "\n",
    "\n",
    "# class mt5PerplexityExperiments:\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model_id: Enum = 'google/mt5-base',\n",
    "#         device: Enum = 'cuda:0',\n",
    "#     ):\n",
    "#         self.device = device\n",
    "#         self.model = MT5ForConditionalGeneration.from_pretrained(model_id).to(device)\n",
    "#         self.tokenizer = T5Tokenizer.from_pretrained(model_id)\n",
    "        \n",
    "#         self.log_dict = {}\n",
    "\n",
    "#     def get_tokenized_dataset(self, datasets, column_name):\n",
    "#         max_seq_length = min(self.max_seq_length, self.tokenizer.model_max_length)\n",
    "#         column_names = datasets[column_name].column_names\n",
    "#         text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
    "        \n",
    "#         tokenized_datasets = datasets.map(\n",
    "#             lambda x: tokenize_function(x, tokenizer=self.tokenizer, text_column_name=text_column_name),\n",
    "#             batched=True,\n",
    "#             num_proc=self.num_proc,\n",
    "#             remove_columns=column_names\n",
    "#         )\n",
    "#         expanded_inputs_length, targets_length = compute_input_and_target_lengths(\n",
    "#             inputs_length=self.max_seq_length,\n",
    "#             noise_density=self.mlm_probability,\n",
    "#             mean_noise_span_length=self.mean_noise_span_length,\n",
    "#         )\n",
    "\n",
    "#         data_collator = FlaxDataCollatorForT5MLM(\n",
    "#             tokenizer=self.tokenizer,\n",
    "#             noise_density=self.mlm_probability,\n",
    "#             mean_noise_span_length=self.mean_noise_span_length,\n",
    "#             input_length=max_seq_length,\n",
    "#             target_length=targets_length,\n",
    "#             pad_token_id=self.model.config.pad_token_id,\n",
    "#             decoder_start_token_id=self.model.config.decoder_start_token_id,\n",
    "#         )\n",
    "\n",
    "#         tokenized_datasets = tokenized_datasets.map(\n",
    "#             lambda x: group_texts(x, expanded_inputs_length=expanded_inputs_length),\n",
    "#             batched=True,\n",
    "#             num_proc=self.num_proc,\n",
    "#         )\n",
    "#         return tokenized_datasets, data_collator\n",
    "\n",
    "\n",
    "#     def training(\n",
    "#         self,\n",
    "#         train_valid_dir: os.PathLike,\n",
    "#         max_dataset_len: int = 500000,\n",
    "#         train_size: float = 0.9,\n",
    "#         n_epochs: int = 5,\n",
    "#         learning_rate: float = 0.005,\n",
    "#         num_warmup_steps: int = 2000,\n",
    "#         weight_decay: float = 0.001,\n",
    "#         betas: Tuple[float, float] = [0.9, 0.999],\n",
    "#         max_seq_length: int = 256,\n",
    "#         per_device_batch_size: int = 64,\n",
    "#         mlm_probability: float = 0.15,\n",
    "#         mean_noise_span_length: int = 3,\n",
    "#         num_proc: Optional[int] = None,\n",
    "#     ):\n",
    "#         self.max_seq_length = max_seq_length\n",
    "#         self.per_device_batch_size = per_device_batch_size\n",
    "#         self.mlm_probability = mlm_probability\n",
    "#         self.mean_noise_span_length = mean_noise_span_length\n",
    "#         self.num_proc = num_proc\n",
    "\n",
    "#         log_params = {\n",
    "#             \"train_valid_dir\":train_valid_dir,\n",
    "#             \"train_size\":train_size,\n",
    "#             \"n_epochs\":n_epochs,\n",
    "#             \"learning_rate\":learning_rate,\n",
    "#             \"num_warmup_steps\":num_warmup_steps,\n",
    "#             \"weight_decay\":weight_decay,\n",
    "#             \"betas\":betas,\n",
    "#             \"max_seq_length\":max_seq_length,\n",
    "#             \"per_device_batch_size\":per_device_batch_size,\n",
    "#             \"mlm_probability\":mlm_probability,\n",
    "#             \"mean_noise_span_length\":mean_noise_span_length,\n",
    "#             \"num_proc\":num_proc\n",
    "#         }\n",
    "#         random_seed = uuid.uuid4()\n",
    "#         save_folder = f'mt5_experiments/training_on_{Path(train_valid_dir).name}/{random_seed}'\n",
    "\n",
    "#         if not os.path.exists(save_folder):\n",
    "#             os.makedirs(save_folder)\n",
    "        \n",
    "#         params_filename = Path(save_folder, \"params.json\")\n",
    "#         log_filename = Path(save_folder, \"log_results.txt\")\n",
    "#         with open(params_filename, \"w\") as outfile:\n",
    "#             json.dump(log_params, outfile, indent=4)\n",
    "\n",
    "#         train_val_paths = [str(Path(train_valid_dir, i)) for i in os.listdir(train_valid_dir)]\n",
    "#         dataset = load_dataset('text', data_files=train_val_paths, split='train')\n",
    "\n",
    "#         dataset_limit = min(len(dataset), max_dataset_len)\n",
    "#         data_indices = np.random.choice(len(dataset), dataset_limit)\n",
    "#         cutted_dataset = dataset.select(data_indices)\n",
    "#         datasets = cutted_dataset.train_test_split(test_size=1-train_size)\n",
    "#         column_name = 'train'\n",
    "\n",
    "#         train_tokenized_datasets, train_data_collator = self.get_tokenized_dataset(datasets, column_name)\n",
    "#         num_train_samples = len(train_tokenized_datasets[column_name])\n",
    "#         train_batch_idx = generate_batch_splits(\n",
    "#             np.arange(num_train_samples),\n",
    "#             self.per_device_batch_size\n",
    "#             )\n",
    "        \n",
    "#         num_train_steps = len(train_tokenized_datasets[\"train\"]) // self.per_device_batch_size * n_epochs\n",
    "        \n",
    "#         optimizer = AdamW(\n",
    "#             self.model.parameters(),\n",
    "#             lr=learning_rate,\n",
    "#             weight_decay = weight_decay,\n",
    "#             betas = betas\n",
    "#             )\n",
    "\n",
    "#         scheduler = get_linear_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps=num_warmup_steps,\n",
    "#                 num_training_steps=num_train_steps\n",
    "#                 )\n",
    "        \n",
    "#         self.log_dict = {\"train\": [], \"val\": []}\n",
    "#         for epoch in trange(n_epochs):\n",
    "#             # ======================== Training ================================\n",
    "#             train_losses_epoch = []\n",
    "\n",
    "#             step = int(len(train_batch_idx) * 0.05)\n",
    "#             for i, batch_idx in tqdm(enumerate(train_batch_idx), desc='Training...', leave=True, total=len(train_batch_idx)):\n",
    "#                 self.model.train()\n",
    "#                 f = open(log_filename, 'a+')\n",
    "       \n",
    "#                 samples = [train_tokenized_datasets[\"train\"][int(idx)] for idx in batch_idx]\n",
    "#                 model_inputs = train_data_collator(samples)\n",
    "#                 model_inputs = shard(model_inputs.data)\n",
    "\n",
    "#                 input_ids = torch.LongTensor(model_inputs['input_ids']).to(self.device)\n",
    "#                 # decoder_input_ids = torch.LongTensor(model_inputs['decoder_input_ids']).to(self.device)\n",
    "#                 labels = torch.LongTensor(model_inputs['labels']).to(self.device)\n",
    "                \n",
    "#                 input_ids_size = input_ids.size()\n",
    "#                 labels_size = labels.size()\n",
    "#                 input_ids = input_ids.reshape([input_ids_size[0], input_ids_size[1] * input_ids_size[2]])\n",
    "#                 labels = labels.reshape([labels_size[0], labels_size[1] * labels_size[2]])\n",
    "                \n",
    "#                 optimizer.zero_grad()\n",
    "                \n",
    "#                 loss = self.model(\n",
    "#                     input_ids=torch.squeeze(input_ids, 0),\n",
    "#                     labels=torch.squeeze(labels, 0)\n",
    "#                 )\n",
    "#                 train_losses_epoch.append(loss.loss.item())\n",
    "#                 loss.loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 scheduler.step()\n",
    "\n",
    "#                 # ======================== Evaluating ==============================\n",
    "#                 if i % step == 0 and i > 0:\n",
    "#                     perp_train = np.exp(np.mean(train_losses_epoch))\n",
    "#                     train_msg = f'TRAIN ITERATION: {i}\\t FOR {train_valid_dir} \\t Perplexity = {perp_train}\\n'\n",
    "#                     print(train_msg)\n",
    "#                     f.write(train_msg)\n",
    "                    \n",
    "#                     self.log_dict[\"train\"].append(perp_train)\n",
    "\n",
    "#                     self.model.eval()\n",
    "\n",
    "#                     with torch.no_grad():\n",
    "#                         column_name = 'test'\n",
    "#                         val_tokenized_datasets, val_data_collator = self.get_tokenized_dataset(datasets, column_name)\n",
    "#                         num_val_samples = len(val_tokenized_datasets[column_name])\n",
    "#                         val_batch_idx = generate_batch_splits(\n",
    "#                             np.arange(num_val_samples),\n",
    "#                             self.per_device_batch_size\n",
    "#                             )\n",
    "#                         val_losses_epoch = []\n",
    "#                         for batch_idx in tqdm(val_batch_idx, desc='Validation...', leave=True):\n",
    "#                             samples = [val_tokenized_datasets[column_name][int(idx)] for idx in batch_idx]\n",
    "#                             model_inputs = val_data_collator(samples)\n",
    "#                             model_inputs = shard(model_inputs.data)\n",
    "\n",
    "#                             input_ids = torch.LongTensor(model_inputs['input_ids']).to(self.device)\n",
    "#                             # decoder_input_ids = torch.LongTensor(model_inputs['decoder_input_ids']).to(self.device)\n",
    "#                             labels = torch.LongTensor(model_inputs['labels']).to(self.device)\n",
    "\n",
    "#                             input_ids_size = input_ids.size()\n",
    "#                             labels_size = labels.size()\n",
    "#                             input_ids = input_ids.reshape([input_ids_size[0], input_ids_size[1] * input_ids_size[2]])\n",
    "#                             labels = labels.reshape([labels_size[0], labels_size[1] * labels_size[2]])\n",
    "#                             loss = self.model(\n",
    "#                                 input_ids=torch.squeeze(input_ids, 0),\n",
    "#                                 labels=torch.squeeze(labels, 0)\n",
    "#                             )\n",
    "#                             val_losses_epoch.append(loss.loss.item())\n",
    "                        \n",
    "#                         perp_val = np.exp(np.mean(val_losses_epoch))\n",
    "#                         val_msg = f'VALIDATION ITERATION: {i}\\t FOR {train_valid_dir} \\t Perplexity = {perp_val}\\n'\n",
    "#                         print(val_msg)\n",
    "#                         f.write(val_msg)\n",
    "                        \n",
    "#                         self.log_dict[\"val\"].append(perp_val)\n",
    "#                         f.close()\n",
    "#                         #torch.save(self.model.state_dict(), Path(save_folder, f'epoch_{epoch}_iteration_{i}.pt'))\n",
    "\n",
    "#     def testing(\n",
    "#         self,\n",
    "#         test_dir: os.PathLike,\n",
    "#         max_seq_length: int = 256,\n",
    "#         per_device_batch_size: int = 64,\n",
    "#         mlm_probability: float = 0.15,\n",
    "#         mean_noise_span_length: int = 3,\n",
    "#         num_proc: Optional[int] = None,\n",
    "#         checkpoint_path: Optional[str] = None\n",
    "#     ):\n",
    "#         self.max_seq_length = max_seq_length\n",
    "#         self.per_device_batch_size = per_device_batch_size\n",
    "#         self.mlm_probability = mlm_probability\n",
    "#         self.mean_noise_span_length = mean_noise_span_length\n",
    "#         self.num_proc = num_proc\n",
    "        \n",
    "#         if checkpoint_path is not None:\n",
    "#             self.model.load_state_dict(torch.load(checkpoint_path, map_location=self.device))\n",
    "    \n",
    "#         test_paths = [str(Path(test_dir, i)) for i in os.listdir(test_dir)]\n",
    "#         datasets = load_dataset('text', data_files=test_paths)\n",
    "\n",
    "#         self.model.eval()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             column_name = 'train'\n",
    "#             test_tokenized_datasets, test_data_collator = self.get_tokenized_dataset(datasets, column_name)\n",
    "#             num_test_samples = len(test_tokenized_datasets[column_name])\n",
    "#             test_batch_idx = generate_batch_splits(\n",
    "#                 np.arange(num_test_samples),\n",
    "#                 self.per_device_batch_size\n",
    "#                 )\n",
    "#             test_losses = []\n",
    "#             for batch_idx in tqdm(test_batch_idx, desc='Testing...', leave=True):\n",
    "#                 samples = [test_tokenized_datasets[column_name][int(idx)] for idx in batch_idx]\n",
    "#                 model_inputs = test_data_collator(samples)\n",
    "#                 model_inputs = shard(model_inputs.data)\n",
    "\n",
    "#                 input_ids = torch.LongTensor(model_inputs['input_ids']).to(self.device)\n",
    "#                 # decoder_input_ids = torch.LongTensor(model_inputs['decoder_input_ids']).to(self.device)\n",
    "#                 labels = torch.LongTensor(model_inputs['labels']).to(self.device)\n",
    "\n",
    "                \n",
    "#                 input_ids_size = input_ids.size()\n",
    "#                 labels_size = labels.size()\n",
    "#                 input_ids = input_ids.reshape([input_ids_size[0], input_ids_size[1] * input_ids_size[2]])\n",
    "#                 labels = labels.reshape([labels_size[0], labels_size[1] * labels_size[2]])\n",
    "#                 loss = self.model(\n",
    "#                     input_ids=torch.squeeze(input_ids, 0),\n",
    "#                     labels=torch.squeeze(labels, 0)\n",
    "#                 )\n",
    "#                 test_losses.append(loss.loss.item())\n",
    "            \n",
    "#             test_msg = (f'TEST: For {test_dir} \\t Perplexity = {np.exp(np.mean(test_losses))}\\n')\n",
    "#             print(test_msg)\n",
    "#             return np.exp(np.mean(test_losses))\n",
    "\n",
    "\n",
    "# def main(\n",
    "#     train_valid_dir: Optional[os.PathLike] = None,\n",
    "#     max_dataset_len: int = 500000,\n",
    "#     train_size: float = 0.9,\n",
    "#     n_epochs: int = 5,\n",
    "#     learning_rate: float = 0.005,\n",
    "#     num_warmup_steps: int = 2000,\n",
    "#     weight_decay: float = 0.001,\n",
    "#     betas: Tuple[float, float] = [0.9, 0.999],\n",
    "#     test_dir: Optional[os.PathLike] = None,\n",
    "#     model_id: Enum = 'google/mt5-base',\n",
    "#     device: Enum = 'cuda:0',\n",
    "#     max_seq_length: int = 256,\n",
    "#     per_device_batch_size: int = 64,\n",
    "#     mlm_probability: float = 0.15,\n",
    "#     mean_noise_span_length: int = 3,\n",
    "#     num_proc: Optional[int] = None\n",
    "# ):\n",
    "#     initialize_experiments = mt5PerplexityExperiments(\n",
    "#         model_id,\n",
    "#         device,\n",
    "#     )\n",
    "#     if train_valid_dir is not None:\n",
    "#         initialize_experiments.training(\n",
    "#             train_valid_dir,\n",
    "#             max_dataset_len,\n",
    "#             train_size,\n",
    "#             n_epochs,\n",
    "#             learning_rate,\n",
    "#             num_warmup_steps,\n",
    "#             weight_decay,\n",
    "#             betas,\n",
    "#             max_seq_length,\n",
    "#             per_device_batch_size,\n",
    "#             mlm_probability,\n",
    "#             mean_noise_span_length,\n",
    "#             num_proc\n",
    "#         )\n",
    "\n",
    "#     if test_dir is not None:\n",
    "#         initialize_experiments.testing(\n",
    "#             test_dir,\n",
    "#             max_seq_length,\n",
    "#             per_device_batch_size,\n",
    "#             mlm_probability,\n",
    "#             mean_noise_span_length,\n",
    "#             num_proc\n",
    "#         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2aa667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    MT5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from flax.training.common_utils import shard\n",
    "from enum import Enum\n",
    "from typing import Optional, Tuple\n",
    "from fire import Fire\n",
    "from math import floor\n",
    "import uuid\n",
    "\n",
    "\n",
    "class mt5PerplexityExperiments:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id: Enum = 'google/mt5-base',\n",
    "        device: Enum = 'cuda:0',\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = MT5ForConditionalGeneration.from_pretrained(model_id).to(device)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_id)\n",
    "        \n",
    "        self.log_dict = {}\n",
    "\n",
    "    def get_tokenized_dataset(self, datasets, column_name):\n",
    "        max_seq_length = min(self.max_seq_length, self.tokenizer.model_max_length)\n",
    "        column_names = datasets[column_name].column_names\n",
    "        text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
    "        \n",
    "        tokenized_datasets = datasets.map(\n",
    "            lambda x: tokenize_function(x, tokenizer=self.tokenizer, text_column_name=text_column_name),\n",
    "            batched=True,\n",
    "            num_proc=self.num_proc,\n",
    "            remove_columns=column_names\n",
    "        )\n",
    "        expanded_inputs_length, targets_length = compute_input_and_target_lengths(\n",
    "            inputs_length=self.max_seq_length,\n",
    "            noise_density=self.mlm_probability,\n",
    "            mean_noise_span_length=self.mean_noise_span_length,\n",
    "        )\n",
    "\n",
    "        data_collator = FlaxDataCollatorForT5MLM(\n",
    "            tokenizer=self.tokenizer,\n",
    "            noise_density=self.mlm_probability,\n",
    "            mean_noise_span_length=self.mean_noise_span_length,\n",
    "            input_length=max_seq_length,\n",
    "            target_length=targets_length,\n",
    "            pad_token_id=self.model.config.pad_token_id,\n",
    "            decoder_start_token_id=self.model.config.decoder_start_token_id,\n",
    "        )\n",
    "\n",
    "        tokenized_datasets = tokenized_datasets.map(\n",
    "            lambda x: group_texts(x, expanded_inputs_length=expanded_inputs_length),\n",
    "            batched=True,\n",
    "            num_proc=self.num_proc,\n",
    "        )\n",
    "        return tokenized_datasets, data_collator\n",
    "\n",
    "\n",
    "    def training(\n",
    "        self,\n",
    "        train_valid_dir: os.PathLike,\n",
    "        max_dataset_len: int = 500000,\n",
    "        train_size: float = 0.9,\n",
    "        n_epochs: int = 5,\n",
    "        learning_rate: float = 0.005,\n",
    "        num_warmup_steps: int = 2000,\n",
    "        weight_decay: float = 0.001,\n",
    "        betas: Tuple[float, float] = [0.9, 0.999],\n",
    "        max_seq_length: int = 256,\n",
    "        per_device_batch_size: int = 64,\n",
    "        mlm_probability: float = 0.15,\n",
    "        mean_noise_span_length: int = 3,\n",
    "        num_proc: Optional[int] = None,\n",
    "        lr_languages_to_test = None\n",
    "    ):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.per_device_batch_size = per_device_batch_size\n",
    "        self.mlm_probability = mlm_probability\n",
    "        self.mean_noise_span_length = mean_noise_span_length\n",
    "        self.num_proc = num_proc\n",
    "\n",
    "        log_params = {\n",
    "            \"train_valid_dir\":train_valid_dir,\n",
    "            \"train_size\":train_size,\n",
    "            \"n_epochs\":n_epochs,\n",
    "            \"learning_rate\":learning_rate,\n",
    "            \"num_warmup_steps\":num_warmup_steps,\n",
    "            \"weight_decay\":weight_decay,\n",
    "            \"betas\":betas,\n",
    "            \"max_seq_length\":max_seq_length,\n",
    "            \"per_device_batch_size\":per_device_batch_size,\n",
    "            \"mlm_probability\":mlm_probability,\n",
    "            \"mean_noise_span_length\":mean_noise_span_length,\n",
    "            \"num_proc\":num_proc\n",
    "        }\n",
    "        random_seed = uuid.uuid4()\n",
    "        self.save_folder = f'mt5_experiments/training_on_{Path(train_valid_dir).name}/{random_seed}'\n",
    "\n",
    "        if not os.path.exists(self.save_folder):\n",
    "            os.makedirs(self.save_folder)\n",
    "        \n",
    "        params_filename = Path(self.save_folder, \"params.json\")\n",
    "        log_filename = Path(self.save_folder, \"log_results.txt\")\n",
    "        log_errors = Path(self.save_folder, \"log_errors.txt\")\n",
    "        new_log_path = Path(self.save_folder, \"new_log.json\")\n",
    "        with open(params_filename, \"w+\") as outfile:\n",
    "            json.dump(log_params, outfile, indent=4)\n",
    "\n",
    "        train_val_paths = [str(Path(train_valid_dir, i)) for i in os.listdir(train_valid_dir)]\n",
    "        dataset = load_dataset('text', data_files=train_val_paths, split='train')\n",
    "\n",
    "        dataset_limit = min(len(dataset), max_dataset_len)\n",
    "        data_indices = np.random.choice(len(dataset), dataset_limit)\n",
    "        cutted_dataset = dataset.select(data_indices)\n",
    "        datasets = cutted_dataset.train_test_split(test_size=1-train_size)\n",
    "        column_name = 'train'\n",
    "\n",
    "        train_tokenized_datasets, train_data_collator = self.get_tokenized_dataset(datasets, column_name)\n",
    "        num_train_samples = len(train_tokenized_datasets[column_name])\n",
    "        train_batch_idx = generate_batch_splits(\n",
    "            np.arange(num_train_samples),\n",
    "            self.per_device_batch_size\n",
    "            )\n",
    "        \n",
    "        num_train_steps = len(train_tokenized_datasets[\"train\"]) // self.per_device_batch_size * n_epochs\n",
    "        \n",
    "        optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay = weight_decay,\n",
    "            betas = betas\n",
    "            )\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=num_warmup_steps,\n",
    "                num_training_steps=num_train_steps\n",
    "                )\n",
    "        \n",
    "        self.log_dict = {\"train\": [], \"val\": [], \"test\": {}}\n",
    "        for epoch in trange(n_epochs):\n",
    "            # ======================== Training ================================\n",
    "            train_losses_epoch = []\n",
    "\n",
    "            step = int(len(train_batch_idx) * 0.05)\n",
    "            for i, batch_idx in tqdm(enumerate(train_batch_idx), desc='Training...', leave=True, total=len(train_batch_idx)):\n",
    "                with open(str(new_log_path), \"w\") as outfile:\n",
    "                    json.dump(self.log_dict, outfile)\n",
    "                \n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                self.model.train()\n",
    "                f = open(log_filename, 'a+')\n",
    "                f_error = open(log_errors, 'a+')\n",
    "       \n",
    "                samples = [train_tokenized_datasets[\"train\"][int(idx)] for idx in batch_idx]\n",
    "                model_inputs = train_data_collator(samples)\n",
    "                model_inputs = shard(model_inputs.data)\n",
    "\n",
    "                input_ids = torch.LongTensor(model_inputs['input_ids']).to(self.device)\n",
    "                labels = torch.LongTensor(model_inputs['labels']).to(self.device)\n",
    "                \n",
    "                input_ids_size = input_ids.size()\n",
    "                labels_size = labels.size()\n",
    "                input_ids = input_ids.reshape([input_ids_size[0], input_ids_size[1] * input_ids_size[2]])\n",
    "                labels = labels.reshape([labels_size[0], labels_size[1] * labels_size[2]])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss = self.model(\n",
    "                    input_ids=torch.squeeze(input_ids, 0),\n",
    "                    labels=torch.squeeze(labels, 0)\n",
    "                )\n",
    "                train_losses_epoch.append(loss.loss.item())\n",
    "                loss.loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                # ======================== Evaluating ==============================\n",
    "                if i % step == 0 and i > 0:\n",
    "                    perp_train = np.exp(np.mean(train_losses_epoch))\n",
    "                    train_msg = f'TRAIN ITERATION: {i}\\t FOR {train_valid_dir} \\t Perplexity = {perp_train}\\n'\n",
    "                    print(train_msg)\n",
    "                    f.write(train_msg)\n",
    "                    \n",
    "                    self.log_dict[\"train\"].append(perp_train)\n",
    "\n",
    "                    self.model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        column_name = 'test'\n",
    "                        val_tokenized_datasets, val_data_collator = self.get_tokenized_dataset(datasets, column_name)\n",
    "                        num_val_samples = len(val_tokenized_datasets[column_name])\n",
    "                        val_batch_idx = generate_batch_splits(\n",
    "                            np.arange(num_val_samples),\n",
    "                            self.per_device_batch_size\n",
    "                            )\n",
    "                        val_losses_epoch = []\n",
    "                        for batch_idx in tqdm(val_batch_idx, desc='Validation...', leave=True):\n",
    "                            samples = [val_tokenized_datasets[column_name][int(idx)] for idx in batch_idx]\n",
    "                            model_inputs = val_data_collator(samples)\n",
    "                            model_inputs = shard(model_inputs.data)\n",
    "\n",
    "                            input_ids = torch.LongTensor(model_inputs['input_ids']).to(self.device)\n",
    "                            labels = torch.LongTensor(model_inputs['labels']).to(self.device)\n",
    "\n",
    "                            input_ids_size = input_ids.size()\n",
    "                            labels_size = labels.size()\n",
    "                            input_ids = input_ids.reshape([input_ids_size[0], input_ids_size[1] * input_ids_size[2]])\n",
    "                            labels = labels.reshape([labels_size[0], labels_size[1] * labels_size[2]])\n",
    "                            loss = self.model(\n",
    "                                input_ids=torch.squeeze(input_ids, 0),\n",
    "                                labels=torch.squeeze(labels, 0)\n",
    "                            )\n",
    "                            val_losses_epoch.append(loss.loss.item())\n",
    "                        \n",
    "                        perp_val = np.exp(np.mean(val_losses_epoch))\n",
    "                        val_msg = f'VALIDATION ITERATION: {i}\\t FOR {train_valid_dir} \\t Perplexity = {perp_val}\\n'\n",
    "                        print(val_msg)\n",
    "                        f.write(val_msg)\n",
    "                        \n",
    "                        self.log_dict[\"val\"].append(perp_val)\n",
    "                        f.close()\n",
    "                        #torch.save(self.model.state_dict(), Path(save_folder, f'epoch_{epoch}_iteration_{i}.pt'))\n",
    "                        \n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        for lr_lang in tqdm(lr_languages_to_test):\n",
    "                            lang_folder_path = str(Path(Path(train_valid_dir).parent, lr_lang))\n",
    "                            try:\n",
    "                                if lang_folder_path not in self.log_dict[\"test\"]:\n",
    "                                    self.log_dict[\"test\"][lang_folder_path] = []\n",
    "                                self.log_dict[\"test\"][lang_folder_path].append(self.testing(lang_folder_path))\n",
    "                            except:\n",
    "                                f_error.write(f\"Something went wrong during processing: {lang_folder_path}\\n\")\n",
    "\n",
    "\n",
    "    def testing(\n",
    "        self,\n",
    "        test_dir: os.PathLike,\n",
    "        max_seq_length: int = 256,\n",
    "        per_device_batch_size: int = 64,\n",
    "        mlm_probability: float = 0.15,\n",
    "        mean_noise_span_length: int = 3,\n",
    "        num_proc: Optional[int] = None,\n",
    "        checkpoint_path: Optional[str] = None\n",
    "    ):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.per_device_batch_size = per_device_batch_size\n",
    "        self.mlm_probability = mlm_probability\n",
    "        self.mean_noise_span_length = mean_noise_span_length\n",
    "        self.num_proc = num_proc\n",
    "        \n",
    "        if checkpoint_path is not None:\n",
    "            self.model.load_state_dict(torch.load(checkpoint_path, map_location=self.device))\n",
    "    \n",
    "        test_paths = [str(Path(test_dir, i)) for i in os.listdir(test_dir)]\n",
    "        datasets = load_dataset('text', data_files=test_paths)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            column_name = 'train'\n",
    "            test_tokenized_datasets, test_data_collator = self.get_tokenized_dataset(datasets, column_name)\n",
    "            num_test_samples = len(test_tokenized_datasets[column_name])\n",
    "            test_batch_idx = generate_batch_splits(\n",
    "                np.arange(num_test_samples),\n",
    "                self.per_device_batch_size\n",
    "                )\n",
    "            test_losses = []\n",
    "            for batch_idx in tqdm(test_batch_idx, desc='Testing...', leave=True):\n",
    "                samples = [test_tokenized_datasets[column_name][int(idx)] for idx in batch_idx]\n",
    "                model_inputs = test_data_collator(samples)\n",
    "                model_inputs = shard(model_inputs.data)\n",
    "\n",
    "                input_ids = torch.LongTensor(model_inputs['input_ids']).to(self.device)\n",
    "                labels = torch.LongTensor(model_inputs['labels']).to(self.device)\n",
    "\n",
    "                input_ids_size = input_ids.size()\n",
    "                labels_size = labels.size()\n",
    "                input_ids = input_ids.reshape([input_ids_size[0], input_ids_size[1] * input_ids_size[2]])\n",
    "                labels = labels.reshape([labels_size[0], labels_size[1] * labels_size[2]])\n",
    "                loss = self.model(\n",
    "                    input_ids=torch.squeeze(input_ids, 0),\n",
    "                    labels=torch.squeeze(labels, 0)\n",
    "                )\n",
    "                test_losses.append(loss.loss.item())\n",
    "            \n",
    "            # test_msg = (f'TEST: For {test_dir} \\t Perplexity = {np.exp(np.mean(test_losses))}\\n')\n",
    "            # print(test_msg)\n",
    "            perp_test = np.exp(np.mean(test_losses))\n",
    "            return perp_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2b9dc",
   "metadata": {},
   "source": [
    "# HR languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec83fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv(\"multilingual/data/Collected_langs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d9bc924",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_languages = df[(df.N_tokens >= 350000)].Name.tolist()\n",
    "lr_languages = df[(df.N_tokens > 10000) & (df.N_tokens < 350000)].Name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b6600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"/home/jovyan/datasets/XL_Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5b3e719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2361728/2856802942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmt5PerplexityExperiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhr_lang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_languages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_languages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HR lang training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     init.training(\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_valid_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mhr_lang\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2361728/3173557747.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_id, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m     ):\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bloom-0/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_contexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bloom-0/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0;31m# Initialize weights and apply final processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bloom-0/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bloom-0/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/issues/57109\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bloom-0/lib/python3.7/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = mt5PerplexityExperiments(device='cuda:0')\n",
    "\n",
    "for hr_lang in tqdm(hr_languages[:len(hr_languages) // 8], desc=\"HR lang training\"):\n",
    "    init.training(\n",
    "        train_valid_dir=dataset_folder+hr_lang,\n",
    "        per_device_batch_size=16,\n",
    "        n_epochs=1,\n",
    "        lr_languages_to_test = lr_languages\n",
    "    )\n",
    "    \n",
    "    params_filename = Path(self.save_folder, \"new_log.json\")\n",
    "    \n",
    "    with open(str(params_filename), \"w\") as outfile:\n",
    "        json.dump(self.log_dict, outfile)\n",
    "        \n",
    "    self.log_dict.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7299caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-5e45f2a0d33243a9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-5e45f2a0d33243a9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8004ce448f48c8873af5474e609a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20652e4215f40ebbc49948711900ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0864ac6ff66478c8550276596118918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96924627f8f44c37b7244c4da78033e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Training...:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "Training...:   2%|         | 1/61 [00:05<05:20,  5.35s/it]\u001b[A\n",
      "Training...:   3%|         | 2/61 [00:09<04:24,  4.49s/it]\u001b[A\n",
      "Training...:   5%|         | 3/61 [00:13<04:26,  4.59s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b37f8e92ab94ef196248d0d9c8bdc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f798cce1b394500a2b5a9424a063a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3992b876a06247eebe3718c42cff9e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e36b1f1d23443e98dffb1186d07f2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...:  17%|        | 1/6 [00:00<00:00,  7.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...:  33%|      | 2/6 [00:00<00:00,  7.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...:  50%|     | 3/6 [00:00<00:00,  8.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...:  67%|   | 4/6 [00:00<00:00,  8.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...:  83%| | 5/6 [00:00<00:00,  8.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...: 100%|| 6/6 [00:00<00:00,  8.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-5e45f2a0d33243a9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-5e45f2a0d33243a9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd86be373ac744ed889e4d5c529489ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1dfe1674b54118a75750360c0c072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e351598b8fc747c98a0a6b3b38b4678c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:12,  1.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:10<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:17<01:08, 17.04s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-07cc36c04b2b5ece\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-07cc36c04b2b5ece/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13058ef3b28e433982330bb9a6eb48e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90edc1f7c2974fb3a5970cf4f78ce883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ad56c0991542b1bbe949033d756557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  17%|        | 1/6 [00:00<00:03,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  33%|      | 2/6 [00:01<00:02,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 3/6 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  67%|   | 4/6 [00:02<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  83%| | 5/6 [00:03<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 6/6 [00:04<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:25<00:35, 11.78s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-41d70eb5a19abbf1\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-41d70eb5a19abbf1/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a96035deba4cd0872c371c042213de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b0f0a566994eb6bf51484998586819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e987d16ab4445a9a589bcddc224134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 1/4 [00:00<00:02,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 2/4 [00:01<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 3/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 4/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:31<00:18,  9.38s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-1204939e39472c75\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-1204939e39472c75/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c147324186414e21a32ce4a84877ffee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13ae9831a104558b7e8591010e4d9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908ab7f5b7f94d61b91e1b14b7911573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:48<00:12, 12.46s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-fdb89b193eb974f9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-fdb89b193eb974f9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116c305a856148f586bcbc9b91c1c19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4339073f39498282cf4fbfc186dc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801d0d4523e84a8ba686da50eb468274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 1/8 [00:00<00:05,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 2/8 [00:01<00:04,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  38%|      | 3/8 [00:02<00:03,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 4/8 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  62%|   | 5/8 [00:03<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 6/8 [00:04<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 7/8 [00:04<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 8/8 [00:05<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:58<00:00, 11.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "Training...:   7%|         | 4/61 [01:27<30:06, 31.70s/it]\u001b[A\n",
      "Training...:   8%|         | 5/61 [01:30<19:59, 21.41s/it]\u001b[A\n",
      "Training...:  10%|         | 6/61 [01:34<14:20, 15.64s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40940067e0da4c779654ae3bd9d8c6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35934c8bced144f9b727f3f78150a04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e2d783e38b4f3fa0e4eae510f1fdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d911a84176e452385febacdbdac1ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation...:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...: 100%|| 1/1 [00:00<00:00,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-5e45f2a0d33243a9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-5e45f2a0d33243a9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c50a42754947c3b9769e6b15dd925e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e37dadca6c47fcb2ad85be91756df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a81f38f73624e2fadaaf6c974a9f492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:16<01:07, 16.93s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-07cc36c04b2b5ece\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-07cc36c04b2b5ece/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c43d384632a4e6aa7134d3334a8d603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966d14a6a7614af09ae90bf6d40ddb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0350d4333d7f4fc7ba001f77cdb437d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  17%|        | 1/6 [00:00<00:03,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  33%|      | 2/6 [00:01<00:02,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 3/6 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  67%|   | 4/6 [00:02<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  83%| | 5/6 [00:03<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 6/6 [00:04<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:25<00:35, 11.77s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-41d70eb5a19abbf1\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-41d70eb5a19abbf1/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12daec990d04eb4906ee18cd6a9aa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bc7effac444557835ee5b76f6f13fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8122c17add684a7783625892c377f1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 1/4 [00:00<00:02,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 2/4 [00:01<00:01,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 3/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 4/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:31<00:18,  9.39s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-1204939e39472c75\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-1204939e39472c75/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28202ed2a28d4588905b26a5aa96c9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e5ef4d358a4b2783b73ae9ac6c58d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e0d4949cf14dc696908f3f6aaa75e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:04<00:07,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:48<00:12, 12.51s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-fdb89b193eb974f9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-fdb89b193eb974f9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dc8e84590b4fd9844da592ee829b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf5e8e81ef94aab8b4cf4966ef061d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8785c4ab0bfc490fb9ceff216d932f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 1/8 [00:00<00:05,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 2/8 [00:01<00:04,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  38%|      | 3/8 [00:02<00:03,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 4/8 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  62%|   | 5/8 [00:03<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 6/8 [00:04<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 7/8 [00:05<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 8/8 [00:05<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:59<00:00, 11.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "Training...:  11%|        | 7/61 [02:48<31:14, 34.71s/it]\u001b[A\n",
      "Training...:  13%|        | 8/61 [02:52<21:58, 24.87s/it]\u001b[A\n",
      "Training...:  15%|        | 9/61 [02:57<16:16, 18.78s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255f47fa8848467489e72a6adc0d68b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e4f6c4a5114ac99b4d28c3080a1e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d6ccc1d5484d379a54bd95f98ad72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e84b6c6e02b4c3b80dcb1f1ecba1d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation...:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...: 100%|| 1/1 [00:00<00:00,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-5e45f2a0d33243a9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-5e45f2a0d33243a9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85bfd7d973840249edb9772400fb5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adb8bc452d14c29942a1069232e6408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ab74c05bac48f1acacf95d509a278e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:12,  1.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:11,  1.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:10<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:17<01:08, 17.20s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-07cc36c04b2b5ece\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-07cc36c04b2b5ece/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8e19756916427694ae96c1f7c38aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b82ee9b6e94c009761d800d557f24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e433c1a8f7476887cd589518dec288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  17%|        | 1/6 [00:00<00:03,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  33%|      | 2/6 [00:01<00:02,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 3/6 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  67%|   | 4/6 [00:02<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  83%| | 5/6 [00:03<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 6/6 [00:04<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:25<00:36, 12.01s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-41d70eb5a19abbf1\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-41d70eb5a19abbf1/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ff64cba9054677a0eb661a241f5c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65e3b0c8e214cc0bf197d35dcc8b42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77358d21806d400c9ae563b11f3aad08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 1/4 [00:00<00:02,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 2/4 [00:01<00:01,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 3/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 4/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:32<00:19,  9.55s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-1204939e39472c75\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-1204939e39472c75/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e965a0c031148c78c5b9f8414420fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fac22e49ef49bfa431730cc56992ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9db69266d64d879e0404413236462e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:04<00:07,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:49<00:12, 12.57s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-fdb89b193eb974f9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-fdb89b193eb974f9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adda839b2eda44b4b29eb32995c435a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f65e18da38046938bc149ea22df4aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29dbe66d8ad47098f8bf58d93946f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 1/8 [00:00<00:05,  1.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 2/8 [00:01<00:04,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  38%|      | 3/8 [00:02<00:03,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 4/8 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  62%|   | 5/8 [00:03<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 6/8 [00:04<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 7/8 [00:05<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 8/8 [00:05<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:59<00:00, 11.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "Training...:  16%|        | 10/61 [04:11<30:21, 35.71s/it]\u001b[A\n",
      "Training...:  18%|        | 11/61 [04:15<21:38, 25.98s/it]\u001b[A\n",
      "Training...:  20%|        | 12/61 [04:20<16:00, 19.59s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c920b66e0cc4b0a96fe2664dd8ebb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a6fbd1fc944787a8b7bd9ebbf5106d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f432dfd87a4bf591292ac224d2b39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790a2d9e10594250b89b32125748e710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation...:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...: 100%|| 1/1 [00:00<00:00,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-5e45f2a0d33243a9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-5e45f2a0d33243a9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0c6403027b47afb20ec79b4154ee9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802983e421634e52b5f0481e923a82f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73763e908944495fbe47848c41c21d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:17<01:08, 17.08s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-07cc36c04b2b5ece\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-07cc36c04b2b5ece/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714e22268c8f4022a431810818c57031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a22114da2a54a6ab4a2ca235377e0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e402e3515f44a28471301a4bd402ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  17%|        | 1/6 [00:00<00:03,  1.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  33%|      | 2/6 [00:01<00:02,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 3/6 [00:02<00:02,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  67%|   | 4/6 [00:02<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  83%| | 5/6 [00:03<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 6/6 [00:04<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:25<00:35, 11.86s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-41d70eb5a19abbf1\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-41d70eb5a19abbf1/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd4ad4405d340c695f6c535fb3ab849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e865fed4bf75450e90d0ec08230cd6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688499535f0242fe854003c9eed58e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 1/4 [00:00<00:02,  1.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 2/4 [00:01<00:01,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 3/4 [00:02<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 4/4 [00:02<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:31<00:18,  9.48s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-1204939e39472c75\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-1204939e39472c75/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de3204fb0d34962af7adc0a9dbeb997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692f81f9f8eb4fc6a270f0b2a1e7f624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd126edfbdf4e6e9381fff7206056e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:49<00:12, 12.52s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-fdb89b193eb974f9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-fdb89b193eb974f9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d80f947e4947a187840f897aaa8f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b34f661e8b4db5894d2dbada137ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033871f4549044d593a7a827853c73d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 1/8 [00:00<00:05,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 2/8 [00:01<00:04,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  38%|      | 3/8 [00:02<00:03,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 4/8 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  62%|   | 5/8 [00:03<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 6/8 [00:04<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 7/8 [00:04<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 8/8 [00:05<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:59<00:00, 11.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "Training...:  21%|       | 13/61 [05:33<28:36, 35.76s/it]\u001b[A\n",
      "Training...:  23%|       | 14/61 [05:36<20:18, 25.92s/it]\u001b[A\n",
      "Training...:  25%|       | 15/61 [05:41<15:02, 19.61s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23264d4c3e00449da5a644ceafcdf375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b7e65969ff46f49e4d60d10c6c6660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028cd0cb6c2f45329e499f9f408252ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711d69231876472da4f9ce72593b2990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation...:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...: 100%|| 1/1 [00:00<00:00,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-5e45f2a0d33243a9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-5e45f2a0d33243a9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cdd514d75849e1af481bc33823698a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da84d8f129be430aac77184fa73a1e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3520cbd2f14acf8077d5459ca4c68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:17<01:08, 17.05s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-07cc36c04b2b5ece\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-07cc36c04b2b5ece/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1eed48ee01845c4b0305fbe19637303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f449aa36f00441c96e8e482b62215df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955763656ed547a092986533d94c9d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  17%|        | 1/6 [00:00<00:03,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  33%|      | 2/6 [00:01<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 3/6 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  67%|   | 4/6 [00:02<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  83%| | 5/6 [00:03<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 6/6 [00:04<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:25<00:35, 11.89s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-41d70eb5a19abbf1\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-41d70eb5a19abbf1/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afed3dd4910c4f938a4fc36b6c453bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ddbe61fc9f41f6bcdffe5a510502ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2eb3ebf6514904ad1be1056f0510c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 1/4 [00:00<00:02,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 2/4 [00:01<00:01,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 3/4 [00:02<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 4/4 [00:02<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:31<00:18,  9.48s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-1204939e39472c75\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-1204939e39472c75/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fc752ac73f4bec8239d53fe5914af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fdcd80184a40608f16fc925946ed7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e013564c0a70444c934aa1c8b82dd40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:04<00:07,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:49<00:12, 12.56s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-fdb89b193eb974f9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-fdb89b193eb974f9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f9969d07074c208ce3ebcd7eefabf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4252ff63044cbfa3a6114dd978c836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ee7cf080134a0ca29765bc52a97561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 1/8 [00:00<00:05,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 2/8 [00:01<00:04,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  38%|      | 3/8 [00:02<00:03,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 4/8 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  62%|   | 5/8 [00:03<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 6/8 [00:04<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 7/8 [00:04<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 8/8 [00:05<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:59<00:00, 11.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "Training...:  26%|       | 16/61 [06:55<27:01, 36.04s/it]\u001b[A\n",
      "Training...:  28%|       | 17/61 [07:00<19:25, 26.48s/it]\u001b[A\n",
      "Training...:  30%|       | 18/61 [07:04<14:15, 19.90s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583ed82fbe584293b19510fc283cef58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8951f2f8b841f0aa18a0cc03082f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ccb61a4c1d4544962ab140a99265f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c948170a0cd43e0a9cab330c3d15ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation...:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...: 100%|| 1/1 [00:00<00:00,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-5e45f2a0d33243a9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-5e45f2a0d33243a9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69f7ac2e0f64961bff3a97872ddbc3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b35ec81c434494b9a3df263c3985535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b45c25ac36420380ac87a84fa5efe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:12,  1.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:17<01:08, 17.08s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-07cc36c04b2b5ece\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-07cc36c04b2b5ece/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a358db275c76404cbd5b9139897f08da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730511b880ec4ee9aff138633b2efe65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82757532f27742e88c7f0be5a595d4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  17%|        | 1/6 [00:00<00:03,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  33%|      | 2/6 [00:01<00:02,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 3/6 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  67%|   | 4/6 [00:02<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  83%| | 5/6 [00:03<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 6/6 [00:04<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:25<00:35, 11.84s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-41d70eb5a19abbf1\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-41d70eb5a19abbf1/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950042d55bb940acb9e6d1c17e99d439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0813afd8198440d96f0d5a3c390a041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87285b968a74481b609a2175cf928b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 1/4 [00:00<00:02,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 2/4 [00:01<00:01,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 3/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 4/4 [00:02<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:31<00:18,  9.44s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-1204939e39472c75\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-1204939e39472c75/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a177535e6b8c4593b11390e3412e36c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d074c46b974aef860e8d6389c06e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418ee5758e0242c287d9ecafc8bed0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:49<00:12, 12.53s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-fdb89b193eb974f9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-fdb89b193eb974f9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63062ab097e642cd9eb45410d212cc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cd53df96114fa2b5da5cdba3b09863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1575f818190e4278b23a38e535ba5901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 1/8 [00:00<00:05,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 2/8 [00:01<00:04,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  38%|      | 3/8 [00:02<00:03,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 4/8 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  62%|   | 5/8 [00:03<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 6/8 [00:04<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 7/8 [00:04<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 8/8 [00:05<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:59<00:00, 11.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "Training...:  31%|       | 19/61 [08:18<25:16, 36.11s/it]\u001b[A\n",
      "Training...:  33%|      | 20/61 [08:22<18:06, 26.51s/it]\u001b[A\n",
      "Training...:  34%|      | 21/61 [08:27<13:16, 19.91s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96013d3d43fa4e7492a2bbf0b1a51d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16e9f6cdc5d41c999bb40a5ed903827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef3744446f44243a110a628cbe9a08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f900ba847274a1097ff5ac3b246aa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation...:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation...: 100%|| 1/1 [00:00<00:00,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-5e45f2a0d33243a9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-5e45f2a0d33243a9/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6be63135bb0458692a8a3533ad765a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32937544fbb64394b642ae4d6f939994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f657fcdf3248f4ba5c53520ce1f073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  41%|      | 7/17 [00:05<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  47%|     | 8/17 [00:05<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  53%|    | 9/17 [00:06<00:05,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  59%|    | 10/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  65%|   | 11/17 [00:07<00:04,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  71%|   | 12/17 [00:08<00:03,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  76%|  | 13/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  82%| | 14/17 [00:09<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  88%| | 15/17 [00:10<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  94%|| 16/17 [00:11<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 17/17 [00:12<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:17<01:08, 17.05s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-07cc36c04b2b5ece\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-07cc36c04b2b5ece/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea533b4f08c44e02afe30dc9ca92e957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc0cc9f37554a3983e589f7095650f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7020081edfa465daa8b3b15d9b98c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  17%|        | 1/6 [00:00<00:03,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  33%|      | 2/6 [00:01<00:02,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 3/6 [00:02<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  67%|   | 4/6 [00:02<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  83%| | 5/6 [00:03<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 6/6 [00:04<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:25<00:35, 11.85s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-41d70eb5a19abbf1\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-41d70eb5a19abbf1/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dffd444525a480ba8004d782498cb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43df5a47e781433ca717007ea81a973f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4216d8853b6041e886b007afca7e8a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  25%|       | 1/4 [00:00<00:02,  1.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  50%|     | 2/4 [00:01<00:01,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  75%|  | 3/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...: 100%|| 4/4 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:31<00:18,  9.48s/it]\u001b[A\u001b[AWARNING:datasets.builder:Using custom data configuration default-1204939e39472c75\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/jovyan/.cache/huggingface/datasets/text/default-1204939e39472c75/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bc7abc472f4fcebf5929253851b07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d993a665b7465cb024019520b0cd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2821026dde442f9efd5dc36f962faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing...:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:   6%|         | 1/17 [00:00<00:11,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  12%|        | 2/17 [00:01<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  18%|        | 3/17 [00:02<00:10,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  24%|       | 4/17 [00:02<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  29%|       | 5/17 [00:03<00:08,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Testing...:  35%|      | 6/17 [00:04<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "init = mt5PerplexityExperiments(device='cuda:0')\n",
    "hr_lang = \"Akan\"\n",
    "init.training(\n",
    "    train_valid_dir=dataset_folder+hr_lang,\n",
    "    per_device_batch_size=16,\n",
    "    n_epochs=1,\n",
    "    lr_languages_to_test = lr_languages[:5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c9c18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
